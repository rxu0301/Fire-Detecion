{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (8.3.202)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (3.10.6)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: psutil in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (1.33.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\pc\\anaconda3\\envs\\test021\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81163cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 48.6MB/s 0.1s.1s<0.0s\n",
      "Transferred 499/499 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.yaml\").load(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d01330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=yolo11n.pt, profile=False, project=run_test01, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 218.770.5 MB/s, size: 51.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\train\\labels... 7673 images, 9 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7673/7673 1.5Kit/s 5.2s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\2308\\Fire Detection.v1i.yolov11\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 264.067.5 MB/s, size: 48.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 1.3Kit/s 0.7s0.1ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache\n",
      "Plotting labels to C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      2.33G      1.507      2.793      1.566         29        640: 100% ━━━━━━━━━━━━ 480/480 8.6it/s 55.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.8it/s 4.3s0.1s\n",
      "                   all        925       1989      0.743      0.706      0.759      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      2.69G      1.477      2.014      1.514         47        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.2it/s 4.7s0.2s\n",
      "                   all        925       1989      0.707      0.632      0.677      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100       2.7G      1.548       1.91      1.574         48        640: 100% ━━━━━━━━━━━━ 480/480 8.7it/s 55.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.8it/s 4.3s0.1s\n",
      "                   all        925       1989      0.778      0.725      0.777      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      2.71G      1.585      1.821      1.617         26        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.8it/s 4.3s0.2s\n",
      "                   all        925       1989      0.789      0.693      0.784      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      2.72G      1.532      1.718      1.593         35        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.856      0.803      0.848      0.666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      2.73G       1.51      1.615      1.562         22        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 53.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.841      0.825      0.854      0.685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      2.75G      1.478      1.582      1.547         25        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 52.7s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.875      0.828      0.868      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      2.75G      1.454      1.529      1.534         43        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 53.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.891      0.838      0.882      0.722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      2.76G       1.41      1.456      1.511         54        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.8it/s 4.3s0.2s\n",
      "                   all        925       1989      0.886      0.822      0.871      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      2.77G        1.4      1.432      1.505         27        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 52.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.892      0.844      0.876      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      2.78G      1.395      1.406      1.485         37        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.7it/s 3.8s0.1s\n",
      "                   all        925       1989      0.892      0.857      0.881       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      2.79G      1.374      1.372      1.478         29        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.1s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.897      0.838      0.888      0.749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100       2.8G       1.37      1.361      1.472         26        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989        0.9       0.87      0.891      0.752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      2.81G      1.334      1.327      1.445         29        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 53.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.8s0.1s\n",
      "                   all        925       1989      0.904      0.865      0.894      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      2.82G      1.322        1.3      1.446         38        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.1s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.909      0.867      0.898      0.762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      2.83G      1.336      1.312      1.448         38        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.909      0.876      0.895      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      2.84G      1.317      1.275      1.438         28        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.915      0.867      0.903      0.775\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      2.85G       1.31      1.256      1.429         33        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.919      0.874      0.901      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      2.86G      1.301      1.247       1.43         31        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.919      0.882      0.905      0.781\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      2.87G      1.287      1.224      1.417         25        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.926      0.884      0.907      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      2.88G      1.288      1.224      1.411         25        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.912       0.87      0.903      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      2.89G       1.29      1.233      1.424         28        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 52.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.6s0.1s\n",
      "                   all        925       1989      0.925      0.871      0.908       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100       2.9G      1.267      1.189      1.401         37        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.919      0.892      0.907       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      2.91G      1.261       1.18      1.388         39        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.917      0.888      0.908      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      2.92G       1.26      1.184      1.391         32        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.6s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.928      0.885      0.913      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      2.93G      1.248       1.16      1.385         19        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.5s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.916      0.893      0.907      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      2.94G      1.233      1.151      1.374         26        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.934      0.882       0.91      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      2.95G      1.233      1.133      1.372         36        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.917      0.889       0.91      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      2.96G      1.231      1.131      1.373         21        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.6s0.1s\n",
      "                   all        925       1989      0.919       0.89      0.913      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      2.97G      1.235      1.133      1.377         39        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.926      0.883      0.912      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      2.98G      1.219      1.106      1.361         32        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.923      0.888      0.911      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      2.99G      1.216      1.113      1.363         26        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.935       0.88      0.914        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100         3G      1.217      1.098      1.358         39        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989       0.92        0.9      0.915      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      3.01G      1.222      1.102      1.361         39        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.931      0.884      0.912      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      3.02G      1.194      1.078      1.348         58        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.929      0.891      0.911      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      3.03G      1.197      1.074      1.345         30        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.915      0.888      0.911      0.809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      3.04G      1.198      1.067      1.346         20        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.8s<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.915      0.895      0.909      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      3.05G      1.193      1.058      1.341         25        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.933       0.89      0.917      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      3.06G       1.18      1.043      1.332         23        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.929      0.884      0.918      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      3.07G      1.177      1.057      1.334         27        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.936      0.895      0.919      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      3.08G      1.184      1.036      1.326         25        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.6s0.1s\n",
      "                   all        925       1989      0.926      0.897      0.914      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      3.09G      1.166       1.04      1.328         36        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.929      0.895      0.913      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100       3.1G      1.164      1.021      1.318         24        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.938      0.889      0.917      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      3.11G      1.165      1.014      1.321         17        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.931      0.892      0.914      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      3.12G      1.157      1.004      1.317         22        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.931      0.893      0.918      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      3.13G      1.149      1.005      1.315         18        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.937      0.892      0.918      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      3.14G      1.158      1.013      1.318         45        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.932      0.899      0.921      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      3.15G      1.138     0.9928      1.305         31        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.938      0.895      0.921      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      3.16G      1.151     0.9992      1.316         37        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.918      0.907       0.92      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      3.17G      1.144     0.9865      1.305         30        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.932      0.897      0.918      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      3.18G      1.121     0.9659      1.293         26        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.8s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.929      0.899      0.923      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      3.19G       1.14     0.9743      1.304         28        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.4s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.1it/s 3.6s0.1s\n",
      "                   all        925       1989      0.929      0.888      0.919      0.822\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100       3.2G      1.129     0.9729      1.296         31        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.923        0.9      0.919      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      3.21G      1.126     0.9689      1.293         25        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.923      0.899      0.922      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      3.22G      1.121     0.9415      1.287         29        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.2s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989       0.93      0.903      0.923      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      3.23G      1.125     0.9539       1.29         26        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989       0.92      0.907      0.921      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      3.24G      1.111     0.9375      1.286         27        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.927      0.899      0.922      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      3.25G      1.114     0.9401      1.283         36        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.927      0.896      0.923      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      3.26G      1.105     0.9262      1.282         37        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.932      0.898      0.923      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      3.27G      1.107     0.9228      1.275         38        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.931      0.906      0.926      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      3.28G      1.086     0.9091       1.26         17        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.937      0.895      0.926      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      3.29G      1.081     0.9035      1.259         18        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.939      0.895      0.927      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100       3.3G      1.098      0.902      1.267         18        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.932        0.9      0.924      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      3.31G      1.073     0.8953      1.258         32        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.932      0.904      0.925      0.836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      3.32G      1.092     0.8948      1.265         20        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.933      0.899      0.924      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      3.33G      1.076     0.8853      1.255         26        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.939      0.897      0.926      0.835\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      3.34G       1.08     0.8807      1.257         21        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.938      0.888      0.923      0.835\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      3.35G      1.072     0.8884       1.26         25        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.937      0.898      0.922       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      3.36G      1.083      0.886      1.258         24        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.938      0.889      0.923      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      3.37G       1.06     0.8625       1.25         35        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.938       0.89      0.923      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      3.38G      1.061     0.8577      1.246         46        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.934      0.891      0.926      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      3.39G      1.054     0.8577      1.239         23        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.7s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.928      0.896      0.923      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100       3.4G      1.049     0.8413      1.237         30        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.944      0.889      0.924      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      3.41G      1.064     0.8643      1.243         39        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989       0.94      0.887      0.925      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      3.42G      1.046     0.8382      1.234         25        640: 100% ━━━━━━━━━━━━ 480/480 9.0it/s 53.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.942      0.889      0.925      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      3.43G      1.051      0.837      1.239         35        640: 100% ━━━━━━━━━━━━ 480/480 8.3it/s 57.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.5it/s 4.4s0.2s\n",
      "                   all        925       1989      0.936      0.892      0.925      0.835\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      3.44G       1.04     0.8268      1.231         25        640: 100% ━━━━━━━━━━━━ 480/480 8.4it/s 57.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.5it/s 4.4s0.2s\n",
      "                   all        925       1989       0.94      0.892      0.926      0.838\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      3.45G      1.038     0.8177      1.225         37        640: 100% ━━━━━━━━━━━━ 480/480 8.1it/s 59.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.7it/s 4.3s0.1s\n",
      "                   all        925       1989      0.926      0.905      0.925      0.835\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      3.46G      1.042     0.8288      1.229         23        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.923        0.9      0.922      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      3.47G      1.035     0.8187      1.222         31        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.927      0.897      0.923      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      3.48G      1.029     0.8076      1.224         22        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.923      0.903      0.923       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      3.49G      1.017     0.8101      1.214         24        640: 100% ━━━━━━━━━━━━ 480/480 8.3it/s 57.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.938      0.885      0.923       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100       3.5G      1.018     0.7999      1.215         15        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.931      0.888      0.922      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      3.51G      1.016     0.7991      1.216         32        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.936      0.889      0.921      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      3.52G      1.011     0.7858      1.213         30        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.3it/s 4.0s0.1s\n",
      "                   all        925       1989      0.936      0.892      0.922      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      3.53G      1.002     0.7803      1.205         34        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.935      0.891      0.919      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      3.54G      1.009     0.7794      1.208         22        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989       0.94      0.889      0.921       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      3.55G     0.9966     0.7704      1.202         30        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.936      0.893      0.921      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      3.56G     0.9996     0.7706      1.208         32        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.929      0.898      0.922      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      3.57G      0.987     0.7646      1.201         32        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.934      0.895      0.923      0.834\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      3.58G     0.9995     0.6835      1.207         25        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.4it/s 3.9s0.1s\n",
      "                   all        925       1989      0.934      0.892      0.923      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      3.59G     0.9839     0.6681      1.199         11        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.935      0.889      0.922      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100       3.6G     0.9706     0.6541      1.189         14        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.7it/s 3.8s0.1s\n",
      "                   all        925       1989       0.93      0.893      0.922      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      3.61G      0.968     0.6479      1.188         15        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.937      0.883      0.921       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      3.62G     0.9604     0.6368      1.181         13        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.7it/s 3.8s0.1s\n",
      "                   all        925       1989      0.922      0.898       0.92      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      3.63G      0.957     0.6337       1.18         20        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.938       0.88       0.92      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      3.64G     0.9513     0.6255      1.179         16        640: 100% ━━━━━━━━━━━━ 480/480 8.7it/s 54.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.7it/s 3.8s0.1s\n",
      "                   all        925       1989      0.932      0.887      0.921      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      3.65G     0.9498     0.6191      1.172         19        640: 100% ━━━━━━━━━━━━ 480/480 8.7it/s 55.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.936      0.884       0.92      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      3.66G     0.9422      0.617      1.169         17        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.934      0.883      0.919      0.827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      3.67G     0.9382       0.61      1.173         17        640: 100% ━━━━━━━━━━━━ 480/480 8.7it/s 55.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.6it/s 3.8s0.1s\n",
      "                   all        925       1989      0.934      0.883      0.919      0.828\n",
      "\n",
      "100 epochs completed in 1.594 hours.\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.5it/s 4.4s0.1s\n",
      "                   all        925       1989       0.94      0.892      0.926      0.838\n",
      "                  Fire        911       1391      0.956      0.935      0.959       0.84\n",
      "                 Smoke        396        598      0.924      0.849      0.892      0.836\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002B6ED4B3490>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.70815707e-02, 8.54078535e-03, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.87123294e-03, 9.35616468e-04, 0.00000000e+00]]), 'Recall', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.29226975, 0.29226975, 0.42133961, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07508845, 0.07508845, 0.11594686, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'F1'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.17174899, 0.17174899, 0.26842233, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.03907529, 0.03907529, 0.06175605, ..., 1.        , 1.        ,\n",
       "        1.        ]]), 'Confidence', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.9798706 , 0.9798706 , 0.97915169, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.95819398, 0.95819398, 0.94648829, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.8380097521359382)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([0.84002511, 0.83599439])\n",
       "names: {0: 'Fire', 1: 'Smoke'}\n",
       "nt_per_class: array([1391,  598])\n",
       "nt_per_image: array([911, 396])\n",
       "results_dict: {'metrics/precision(B)': 0.9397701202926074, 'metrics/recall(B)': 0.8923759448505486, 'metrics/mAP50(B)': 0.9256190479796071, 'metrics/mAP50-95(B)': 0.8380097521359382, 'fitness': 0.8380097521359382}\n",
       "save_dir: WindowsPath('C:/2308/Fire Detection.v1i.yolov11/run_test01/train')\n",
       "speed: {'preprocess': 0.13708713505341596, 'inference': 1.2849438918842557, 'loss': 0.0006031351654815512, 'postprocess': 0.8328905947053352}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(data='data.yaml', epochs=100, batch=16, imgsz=640,project='run_test01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c57f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\augmentation\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=augmentation2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=run_test01, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\augmentation2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 94/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 249.689.9 MB/s, size: 50.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\train\\labels.cache... 7673 images, 9 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7673/7673  0.0s\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=20,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    project='run_test01',\n",
    "    name='augmentation',\n",
    "    mosaic=1.0,       # 모자이크 증강\n",
    "    mixup=0.2,        # MixUp 비율\n",
    "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,  # 색상 변화\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58649d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=regularization, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=run_test01, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 349.9134.8 MB/s, size: 50.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\train\\labels.cache... 7673 images, 9 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7673/7673 477.0Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 249.2132.1 MB/s, size: 50.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "Plotting labels to C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.35G      1.341      1.313      1.453         40        640: 100% ━━━━━━━━━━━━ 480/480 8.2it/s 58.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.1it/s 3.6s0.1s\n",
      "                   all        925       1989       0.86      0.802      0.868      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30       2.7G      1.532      1.634      1.604         39        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 52.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.6s0.1s\n",
      "                   all        925       1989      0.863      0.799      0.861        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30       2.7G      1.561      1.698      1.624         51        640: 100% ━━━━━━━━━━━━ 480/480 9.2it/s 52.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.1it/s 3.6s0.1s\n",
      "                   all        925       1989      0.825      0.802      0.857      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30       2.7G      1.532      1.643      1.604         26        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.878      0.814      0.872      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30       2.7G      1.467      1.547      1.554         42        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.901      0.846      0.889       0.72\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30       2.7G      1.445      1.508      1.543         24        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.1s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.874      0.857      0.879      0.736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30       2.7G      1.404      1.458      1.513         31        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.6s0.1s\n",
      "                   all        925       1989      0.897      0.862      0.891      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30       2.7G      1.396      1.439      1.504         27        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.2s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.865      0.847      0.884       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30       2.7G       1.39       1.42      1.505         32        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.904      0.871      0.894      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      2.71G       1.35      1.371      1.477         42        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.903      0.865      0.895       0.77\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      2.71G      1.342      1.361      1.474         26        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.913      0.876      0.903      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      2.71G      1.324       1.32      1.463         34        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.3s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.6s0.1s\n",
      "                   all        925       1989      0.922      0.869      0.903      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      2.71G       1.32      1.333       1.46         50        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.3s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.916      0.888      0.906      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      2.71G      1.295      1.291      1.443         24        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.4s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989       0.92      0.873      0.902      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      2.71G      1.287      1.282      1.432         28        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.916      0.889       0.91      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      2.71G       1.27      1.256      1.427         37        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.924      0.885       0.91      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      2.71G      1.292      1.263      1.439         25        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989       0.92      0.893      0.912      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      2.71G      1.246      1.228       1.42         36        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.933       0.88      0.911      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      2.71G      1.244      1.211      1.412         30        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.935      0.884      0.915       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      2.71G      1.232      1.179      1.399         28        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.927      0.888      0.915      0.814\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      2.71G      1.209      1.003      1.388         14        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.3it/s 3.5s0.1s\n",
      "                   all        925       1989      0.922      0.895      0.914       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      2.71G      1.199     0.9801      1.383         17        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.928      0.888      0.915      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      2.71G      1.179     0.9384      1.361         15        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.939      0.883      0.914      0.817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      2.71G       1.16     0.9162       1.35         12        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.923        0.9      0.914      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      2.71G      1.141     0.8966      1.339         12        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.3it/s 3.5s0.1s\n",
      "                   all        925       1989      0.927      0.895      0.915      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      2.71G      1.129     0.8678      1.325         14        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.3it/s 3.5s0.1s\n",
      "                   all        925       1989      0.923      0.891      0.918       0.82\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      2.71G      1.111     0.8358      1.312         12        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.4s<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.3it/s 3.5s0.1s\n",
      "                   all        925       1989      0.927      0.897      0.922      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      2.71G      1.094     0.8242      1.302          9        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.931      0.896      0.923      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      2.71G      1.069     0.7996      1.284         12        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 50.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.933      0.894      0.925      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      2.71G      1.062     0.7834      1.274         17        640: 100% ━━━━━━━━━━━━ 480/480 9.5it/s 50.8s<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.3it/s 3.5s0.1s\n",
      "                   all        925       1989      0.935      0.896      0.926       0.83\n",
      "\n",
      "30 epochs completed in 0.465 hours.\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization\\weights\\best.pt...\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.1it/s 4.1s0.1s\n",
      "                   all        925       1989      0.934      0.896      0.926       0.83\n",
      "                  Fire        911       1391      0.945      0.935      0.958      0.828\n",
      "                 Smoke        396        598      0.924      0.858      0.893      0.831\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002B6D7779110>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.66719256e-02, 8.33596279e-03, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.41246883e-03, 7.06234413e-04, 0.00000000e+00]]), 'Recall', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.25071068, 0.25071068, 0.36774338, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.06165308, 0.06165308, 0.09435773, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'F1'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.14368299, 0.14368299, 0.22623035, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.03185495, 0.03185495, 0.04964933, ..., 1.        , 1.        ,\n",
       "        1.        ]]), 'Confidence', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.98274623, 0.98274623, 0.98202732, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.9548495 , 0.9548495 , 0.94816054, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.8295628235618256)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([0.82840484, 0.8307208 ])\n",
       "names: {0: 'Fire', 1: 'Smoke'}\n",
       "nt_per_class: array([1391,  598])\n",
       "nt_per_image: array([911, 396])\n",
       "results_dict: {'metrics/precision(B)': 0.9344117467001142, 'metrics/recall(B)': 0.8963803940845794, 'metrics/mAP50(B)': 0.9256898767166322, 'metrics/mAP50-95(B)': 0.8295628235618256, 'fitness': 0.8295628235618256}\n",
       "save_dir: WindowsPath('C:/2308/Fire Detection.v1i.yolov11/run_test01/regularization')\n",
       "speed: {'preprocess': 0.12556832428467837, 'inference': 1.2524781621224876, 'loss': 0.00022216221770724736, 'postprocess': 0.7837964325035747}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=30,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    project='run_test01',\n",
    "    name='regularization',\n",
    "    weight_decay=0.0005,      # 가중치 감소\n",
    "    optimizer='AdamW',         # 안정적 최적화\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e9b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=[0, 1, 2, 3], half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=freeze_backbone, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=run_test01, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 215.081.5 MB/s, size: 50.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\train\\labels.cache... 7673 images, 9 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7673/7673  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 254.2123.6 MB/s, size: 50.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "Plotting labels to C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/10      1.73G      1.099     0.8237      1.294         16        640: 100% ━━━━━━━━━━━━ 480/480 9.7it/s 49.7ss<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.918      0.885      0.913      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/10      2.09G      1.197      0.939      1.363         14        640: 100% ━━━━━━━━━━━━ 480/480 10.7it/s 44.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.906      0.807      0.868      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/10      2.09G      1.229     0.9879      1.388         11        640: 100% ━━━━━━━━━━━━ 480/480 11.1it/s 43.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.918       0.88      0.903      0.767\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/10      2.09G      1.223     0.9864       1.39         20        640: 100% ━━━━━━━━━━━━ 480/480 11.2it/s 42.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.926      0.859      0.906      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/10      2.09G      1.209     0.9598       1.37         15        640: 100% ━━━━━━━━━━━━ 480/480 11.1it/s 43.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.917       0.88      0.912       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/10      2.09G      1.178     0.9153      1.348         11        640: 100% ━━━━━━━━━━━━ 480/480 11.2it/s 42.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.929       0.87       0.91      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/10      2.11G      1.142     0.8748       1.33         14        640: 100% ━━━━━━━━━━━━ 480/480 11.2it/s 42.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.932      0.889      0.914      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/10      2.11G      1.114     0.8294      1.305         19        640: 100% ━━━━━━━━━━━━ 480/480 11.2it/s 42.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.939      0.885      0.919      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/10      2.11G      1.088     0.7875      1.281         16        640: 100% ━━━━━━━━━━━━ 480/480 11.2it/s 42.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.931      0.887      0.918       0.82\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/10      2.11G      1.055     0.7496      1.259         17        640: 100% ━━━━━━━━━━━━ 480/480 11.1it/s 43.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.931      0.894      0.921      0.828\n",
      "\n",
      "10 epochs completed in 0.138 hours.\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone\\weights\\best.pt...\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.8it/s 4.3s0.1s\n",
      "                   all        925       1989      0.931      0.893      0.921      0.828\n",
      "                  Fire        911       1391      0.944      0.932      0.956      0.831\n",
      "                 Smoke        396        598      0.918      0.855      0.887      0.825\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone\u001b[0m\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=[], half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=unfreeze_all, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=run_test01, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 353.7139.1 MB/s, size: 50.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\train\\labels.cache... 7673 images, 9 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7673/7673 4.4Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 337.2158.2 MB/s, size: 50.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 1.9Mit/s 0.0s\n",
      "Plotting labels to C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.38G      1.245      1.198      1.409         40        640: 100% ━━━━━━━━━━━━ 480/480 8.0it/s 1:00<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989       0.93      0.897      0.922      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.74G      1.188      1.102      1.371         39        640: 100% ━━━━━━━━━━━━ 480/480 8.5it/s 56.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.939      0.889      0.922      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.74G      1.172      1.074      1.356         51        640: 100% ━━━━━━━━━━━━ 480/480 8.4it/s 57.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.7it/s 3.8s0.1s\n",
      "                   all        925       1989      0.939      0.898      0.923      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.74G      1.169      1.062      1.345         26        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.5it/s 3.9s0.1s\n",
      "                   all        925       1989      0.936      0.894      0.921      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.74G      1.147      1.049      1.333         42        640: 100% ━━━━━━━━━━━━ 480/480 8.6it/s 55.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.933      0.894      0.922      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.74G      1.142       1.03      1.336         24        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.7it/s 3.8s0.1s\n",
      "                   all        925       1989      0.935      0.893      0.922      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.74G      1.122      1.016      1.318         31        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.928      0.893      0.923      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.74G      1.132      1.028      1.324         27        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.925        0.9      0.922      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.74G      1.142       1.03      1.332         32        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.934      0.893      0.925      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.74G      1.118      1.004      1.316         42        640: 100% ━━━━━━━━━━━━ 480/480 8.8it/s 54.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989       0.93      0.892      0.922      0.828\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.74G      1.027     0.7551      1.244         17        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.934      0.892      0.922      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.74G      1.018      0.726      1.238         14        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.926      0.895      0.924      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.74G      1.018     0.7163      1.237         22        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.925      0.893      0.921      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.75G      1.008     0.7041      1.231         24        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.929      0.894      0.924      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.75G      1.011     0.7066      1.231         16        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.932      0.898      0.925      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.75G      1.001     0.6953      1.228         29        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.942      0.894      0.925      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.75G     0.9998     0.6952      1.224         21        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 53.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.939      0.893      0.926      0.834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.75G     0.9892     0.6864      1.217         13        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.7it/s 3.8s0.1s\n",
      "                   all        925       1989      0.937       0.89      0.925       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.75G     0.9942     0.6831      1.216         18        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.938      0.888      0.925      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.75G     0.9858     0.6822      1.216         13        640: 100% ━━━━━━━━━━━━ 480/480 8.9it/s 54.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.8it/s 3.7s0.1s\n",
      "                   all        925       1989      0.937      0.888      0.926      0.834\n",
      "\n",
      "20 epochs completed in 0.331 hours.\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all\\weights\\best.pt...\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 6.8it/s 4.3s0.1s\n",
      "                   all        925       1989      0.938      0.888      0.926      0.834\n",
      "                  Fire        911       1391      0.952      0.931       0.96      0.835\n",
      "                 Smoke        396        598      0.924      0.844      0.892      0.833\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002B6C9567F90>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.80114395e-02, 9.00571973e-03, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.98110886e-03, 9.90554428e-04, 0.00000000e+00]]), 'Recall', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.27767049, 0.27767049, 0.40140603, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.076274  , 0.076274  , 0.11942374, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'F1'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.16169508, 0.16169508, 0.25230617, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.03971494, 0.03971494, 0.06371   , ..., 1.        , 1.        ,\n",
       "        1.        ]]), 'Confidence', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.98202732, 0.98202732, 0.98130841, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.95986622, 0.95986622, 0.95150502, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.834159372245996)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([0.83547625, 0.83284249])\n",
       "names: {0: 'Fire', 1: 'Smoke'}\n",
       "nt_per_class: array([1391,  598])\n",
       "nt_per_image: array([911, 396])\n",
       "results_dict: {'metrics/precision(B)': 0.937947469153008, 'metrics/recall(B)': 0.8878991281469949, 'metrics/mAP50(B)': 0.9259334303192364, 'metrics/mAP50-95(B)': 0.834159372245996, 'fitness': 0.834159372245996}\n",
       "save_dir: WindowsPath('C:/2308/Fire Detection.v1i.yolov11/run_test01/unfreeze_all')\n",
       "speed: {'preprocess': 0.13812897305281177, 'inference': 1.3306941622175983, 'loss': 0.00019891882894208305, 'postprocess': 0.7758034594558381}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=10,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    project='run_test01',\n",
    "    name='freeze_backbone',\n",
    "    freeze=[0, 1, 2, 3]  # 초기 레이어 freeze\n",
    ")\n",
    "\n",
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=20,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    project='run_test01',\n",
    "    name='unfreeze_all',\n",
    "    freeze=[],            # 전체 레이어 학습\n",
    "    lr0=0.001             # learning rate 낮춰서 안정적 fine-tuning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d7716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=[], half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=final_tuning, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=run_fire_exp5, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\2308\\Fire Detection.v1i.yolov11\\run_fire_exp5\\final_tuning, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 309.6144.7 MB/s, size: 50.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\train\\labels.cache... 7673 images, 9 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7673/7673  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 353.4168.1 MB/s, size: 50.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 925.3Kit/s 0.0s\n",
      "Plotting labels to C:\\2308\\Fire Detection.v1i.yolov11\\run_fire_exp5\\final_tuning\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_fire_exp5\\final_tuning\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      2.38G      1.156      1.048      1.342         40        640: 100% ━━━━━━━━━━━━ 480/480 8.0it/s 1:00<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.9it/s 3.7s0.1s\n",
      "                   all        925       1989      0.938      0.899      0.925      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      2.73G      1.117      1.012      1.321         39        640: 100% ━━━━━━━━━━━━ 480/480 8.7it/s 55.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.0it/s 3.6s0.1s\n",
      "                   all        925       1989      0.938        0.9      0.926      0.835\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      2.73G       1.11     0.9936      1.313         51        640: 100% ━━━━━━━━━━━━ 480/480 9.1it/s 52.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.3it/s 3.5s0.1s\n",
      "                   all        925       1989      0.938      0.899      0.925      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      2.73G      1.114     0.9894      1.307         26        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.943      0.891      0.922      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      2.73G      1.098     0.9837      1.298         42        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.942      0.888      0.924      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      2.73G      1.096     0.9714      1.303         24        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.931      0.894      0.923      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      2.73G      1.082     0.9615       1.29         31        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.934      0.886      0.922      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      2.73G      1.095     0.9761      1.296         27        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.6s0.1s\n",
      "                   all        925       1989      0.936      0.894      0.923      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      2.73G      1.109     0.9841      1.307         32        640: 100% ━━━━━━━━━━━━ 480/480 9.4it/s 51.1s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.935      0.895      0.924      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      2.73G      1.087     0.9605      1.292         42        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989       0.93      0.893      0.923      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      2.73G      1.112     0.9834      1.308         26        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.4s<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.2it/s 3.5s0.1s\n",
      "                   all        925       1989      0.935      0.884      0.919      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      2.75G      1.106     0.9719      1.309         34        640: 100% ━━━━━━━━━━━━ 480/480 9.3it/s 51.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 8.3it/s 3.5s0.1s\n",
      "                   all        925       1989      0.935        0.9      0.924      0.834\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 2, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "12 epochs completed in 0.188 hours.\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_fire_exp5\\final_tuning\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\2308\\Fire Detection.v1i.yolov11\\run_fire_exp5\\final_tuning\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\2308\\Fire Detection.v1i.yolov11\\run_fire_exp5\\final_tuning\\weights\\best.pt...\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 29/29 7.2it/s 4.0s0.1s\n",
      "                   all        925       1989      0.938        0.9      0.926      0.835\n",
      "                  Fire        911       1391      0.945      0.945      0.957      0.835\n",
      "                 Smoke        396        598      0.931      0.856      0.894      0.835\n",
      "Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\run_fire_exp5\\final_tuning\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002B517844E50>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.09110658e-02, 5.45553289e-03, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.54672463e-03, 7.73362314e-04, 0.00000000e+00]]), 'Recall', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.21607881, 0.21607881, 0.32877334, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.06007326, 0.06007326, 0.09505374, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'F1'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.12146111, 0.12146111, 0.19764129, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.03100691, 0.03100691, 0.05003489, ..., 1.        , 1.        ,\n",
       "        1.        ]]), 'Confidence', 'Precision'], [array([0.        , 0.001001  , 0.002002  , 0.003003  , 0.004004  ,\n",
       "       0.00500501, 0.00600601, 0.00700701, 0.00800801, 0.00900901,\n",
       "       0.01001001, 0.01101101, 0.01201201, 0.01301301, 0.01401401,\n",
       "       0.01501502, 0.01601602, 0.01701702, 0.01801802, 0.01901902,\n",
       "       0.02002002, 0.02102102, 0.02202202, 0.02302302, 0.02402402,\n",
       "       0.02502503, 0.02602603, 0.02702703, 0.02802803, 0.02902903,\n",
       "       0.03003003, 0.03103103, 0.03203203, 0.03303303, 0.03403403,\n",
       "       0.03503504, 0.03603604, 0.03703704, 0.03803804, 0.03903904,\n",
       "       0.04004004, 0.04104104, 0.04204204, 0.04304304, 0.04404404,\n",
       "       0.04504505, 0.04604605, 0.04704705, 0.04804805, 0.04904905,\n",
       "       0.05005005, 0.05105105, 0.05205205, 0.05305305, 0.05405405,\n",
       "       0.05505506, 0.05605606, 0.05705706, 0.05805806, 0.05905906,\n",
       "       0.06006006, 0.06106106, 0.06206206, 0.06306306, 0.06406406,\n",
       "       0.06506507, 0.06606607, 0.06706707, 0.06806807, 0.06906907,\n",
       "       0.07007007, 0.07107107, 0.07207207, 0.07307307, 0.07407407,\n",
       "       0.07507508, 0.07607608, 0.07707708, 0.07807808, 0.07907908,\n",
       "       0.08008008, 0.08108108, 0.08208208, 0.08308308, 0.08408408,\n",
       "       0.08508509, 0.08608609, 0.08708709, 0.08808809, 0.08908909,\n",
       "       0.09009009, 0.09109109, 0.09209209, 0.09309309, 0.09409409,\n",
       "       0.0950951 , 0.0960961 , 0.0970971 , 0.0980981 , 0.0990991 ,\n",
       "       0.1001001 , 0.1011011 , 0.1021021 , 0.1031031 , 0.1041041 ,\n",
       "       0.10510511, 0.10610611, 0.10710711, 0.10810811, 0.10910911,\n",
       "       0.11011011, 0.11111111, 0.11211211, 0.11311311, 0.11411411,\n",
       "       0.11511512, 0.11611612, 0.11711712, 0.11811812, 0.11911912,\n",
       "       0.12012012, 0.12112112, 0.12212212, 0.12312312, 0.12412412,\n",
       "       0.12512513, 0.12612613, 0.12712713, 0.12812813, 0.12912913,\n",
       "       0.13013013, 0.13113113, 0.13213213, 0.13313313, 0.13413413,\n",
       "       0.13513514, 0.13613614, 0.13713714, 0.13813814, 0.13913914,\n",
       "       0.14014014, 0.14114114, 0.14214214, 0.14314314, 0.14414414,\n",
       "       0.14514515, 0.14614615, 0.14714715, 0.14814815, 0.14914915,\n",
       "       0.15015015, 0.15115115, 0.15215215, 0.15315315, 0.15415415,\n",
       "       0.15515516, 0.15615616, 0.15715716, 0.15815816, 0.15915916,\n",
       "       0.16016016, 0.16116116, 0.16216216, 0.16316316, 0.16416416,\n",
       "       0.16516517, 0.16616617, 0.16716717, 0.16816817, 0.16916917,\n",
       "       0.17017017, 0.17117117, 0.17217217, 0.17317317, 0.17417417,\n",
       "       0.17517518, 0.17617618, 0.17717718, 0.17817818, 0.17917918,\n",
       "       0.18018018, 0.18118118, 0.18218218, 0.18318318, 0.18418418,\n",
       "       0.18518519, 0.18618619, 0.18718719, 0.18818819, 0.18918919,\n",
       "       0.19019019, 0.19119119, 0.19219219, 0.19319319, 0.19419419,\n",
       "       0.1951952 , 0.1961962 , 0.1971972 , 0.1981982 , 0.1991992 ,\n",
       "       0.2002002 , 0.2012012 , 0.2022022 , 0.2032032 , 0.2042042 ,\n",
       "       0.20520521, 0.20620621, 0.20720721, 0.20820821, 0.20920921,\n",
       "       0.21021021, 0.21121121, 0.21221221, 0.21321321, 0.21421421,\n",
       "       0.21521522, 0.21621622, 0.21721722, 0.21821822, 0.21921922,\n",
       "       0.22022022, 0.22122122, 0.22222222, 0.22322322, 0.22422422,\n",
       "       0.22522523, 0.22622623, 0.22722723, 0.22822823, 0.22922923,\n",
       "       0.23023023, 0.23123123, 0.23223223, 0.23323323, 0.23423423,\n",
       "       0.23523524, 0.23623624, 0.23723724, 0.23823824, 0.23923924,\n",
       "       0.24024024, 0.24124124, 0.24224224, 0.24324324, 0.24424424,\n",
       "       0.24524525, 0.24624625, 0.24724725, 0.24824825, 0.24924925,\n",
       "       0.25025025, 0.25125125, 0.25225225, 0.25325325, 0.25425425,\n",
       "       0.25525526, 0.25625626, 0.25725726, 0.25825826, 0.25925926,\n",
       "       0.26026026, 0.26126126, 0.26226226, 0.26326326, 0.26426426,\n",
       "       0.26526527, 0.26626627, 0.26726727, 0.26826827, 0.26926927,\n",
       "       0.27027027, 0.27127127, 0.27227227, 0.27327327, 0.27427427,\n",
       "       0.27527528, 0.27627628, 0.27727728, 0.27827828, 0.27927928,\n",
       "       0.28028028, 0.28128128, 0.28228228, 0.28328328, 0.28428428,\n",
       "       0.28528529, 0.28628629, 0.28728729, 0.28828829, 0.28928929,\n",
       "       0.29029029, 0.29129129, 0.29229229, 0.29329329, 0.29429429,\n",
       "       0.2952953 , 0.2962963 , 0.2972973 , 0.2982983 , 0.2992993 ,\n",
       "       0.3003003 , 0.3013013 , 0.3023023 , 0.3033033 , 0.3043043 ,\n",
       "       0.30530531, 0.30630631, 0.30730731, 0.30830831, 0.30930931,\n",
       "       0.31031031, 0.31131131, 0.31231231, 0.31331331, 0.31431431,\n",
       "       0.31531532, 0.31631632, 0.31731732, 0.31831832, 0.31931932,\n",
       "       0.32032032, 0.32132132, 0.32232232, 0.32332332, 0.32432432,\n",
       "       0.32532533, 0.32632633, 0.32732733, 0.32832833, 0.32932933,\n",
       "       0.33033033, 0.33133133, 0.33233233, 0.33333333, 0.33433433,\n",
       "       0.33533534, 0.33633634, 0.33733734, 0.33833834, 0.33933934,\n",
       "       0.34034034, 0.34134134, 0.34234234, 0.34334334, 0.34434434,\n",
       "       0.34534535, 0.34634635, 0.34734735, 0.34834835, 0.34934935,\n",
       "       0.35035035, 0.35135135, 0.35235235, 0.35335335, 0.35435435,\n",
       "       0.35535536, 0.35635636, 0.35735736, 0.35835836, 0.35935936,\n",
       "       0.36036036, 0.36136136, 0.36236236, 0.36336336, 0.36436436,\n",
       "       0.36536537, 0.36636637, 0.36736737, 0.36836837, 0.36936937,\n",
       "       0.37037037, 0.37137137, 0.37237237, 0.37337337, 0.37437437,\n",
       "       0.37537538, 0.37637638, 0.37737738, 0.37837838, 0.37937938,\n",
       "       0.38038038, 0.38138138, 0.38238238, 0.38338338, 0.38438438,\n",
       "       0.38538539, 0.38638639, 0.38738739, 0.38838839, 0.38938939,\n",
       "       0.39039039, 0.39139139, 0.39239239, 0.39339339, 0.39439439,\n",
       "       0.3953954 , 0.3963964 , 0.3973974 , 0.3983984 , 0.3993994 ,\n",
       "       0.4004004 , 0.4014014 , 0.4024024 , 0.4034034 , 0.4044044 ,\n",
       "       0.40540541, 0.40640641, 0.40740741, 0.40840841, 0.40940941,\n",
       "       0.41041041, 0.41141141, 0.41241241, 0.41341341, 0.41441441,\n",
       "       0.41541542, 0.41641642, 0.41741742, 0.41841842, 0.41941942,\n",
       "       0.42042042, 0.42142142, 0.42242242, 0.42342342, 0.42442442,\n",
       "       0.42542543, 0.42642643, 0.42742743, 0.42842843, 0.42942943,\n",
       "       0.43043043, 0.43143143, 0.43243243, 0.43343343, 0.43443443,\n",
       "       0.43543544, 0.43643644, 0.43743744, 0.43843844, 0.43943944,\n",
       "       0.44044044, 0.44144144, 0.44244244, 0.44344344, 0.44444444,\n",
       "       0.44544545, 0.44644645, 0.44744745, 0.44844845, 0.44944945,\n",
       "       0.45045045, 0.45145145, 0.45245245, 0.45345345, 0.45445445,\n",
       "       0.45545546, 0.45645646, 0.45745746, 0.45845846, 0.45945946,\n",
       "       0.46046046, 0.46146146, 0.46246246, 0.46346346, 0.46446446,\n",
       "       0.46546547, 0.46646647, 0.46746747, 0.46846847, 0.46946947,\n",
       "       0.47047047, 0.47147147, 0.47247247, 0.47347347, 0.47447447,\n",
       "       0.47547548, 0.47647648, 0.47747748, 0.47847848, 0.47947948,\n",
       "       0.48048048, 0.48148148, 0.48248248, 0.48348348, 0.48448448,\n",
       "       0.48548549, 0.48648649, 0.48748749, 0.48848849, 0.48948949,\n",
       "       0.49049049, 0.49149149, 0.49249249, 0.49349349, 0.49449449,\n",
       "       0.4954955 , 0.4964965 , 0.4974975 , 0.4984985 , 0.4994995 ,\n",
       "       0.5005005 , 0.5015015 , 0.5025025 , 0.5035035 , 0.5045045 ,\n",
       "       0.50550551, 0.50650651, 0.50750751, 0.50850851, 0.50950951,\n",
       "       0.51051051, 0.51151151, 0.51251251, 0.51351351, 0.51451451,\n",
       "       0.51551552, 0.51651652, 0.51751752, 0.51851852, 0.51951952,\n",
       "       0.52052052, 0.52152152, 0.52252252, 0.52352352, 0.52452452,\n",
       "       0.52552553, 0.52652653, 0.52752753, 0.52852853, 0.52952953,\n",
       "       0.53053053, 0.53153153, 0.53253253, 0.53353353, 0.53453453,\n",
       "       0.53553554, 0.53653654, 0.53753754, 0.53853854, 0.53953954,\n",
       "       0.54054054, 0.54154154, 0.54254254, 0.54354354, 0.54454454,\n",
       "       0.54554555, 0.54654655, 0.54754755, 0.54854855, 0.54954955,\n",
       "       0.55055055, 0.55155155, 0.55255255, 0.55355355, 0.55455455,\n",
       "       0.55555556, 0.55655656, 0.55755756, 0.55855856, 0.55955956,\n",
       "       0.56056056, 0.56156156, 0.56256256, 0.56356356, 0.56456456,\n",
       "       0.56556557, 0.56656657, 0.56756757, 0.56856857, 0.56956957,\n",
       "       0.57057057, 0.57157157, 0.57257257, 0.57357357, 0.57457457,\n",
       "       0.57557558, 0.57657658, 0.57757758, 0.57857858, 0.57957958,\n",
       "       0.58058058, 0.58158158, 0.58258258, 0.58358358, 0.58458458,\n",
       "       0.58558559, 0.58658659, 0.58758759, 0.58858859, 0.58958959,\n",
       "       0.59059059, 0.59159159, 0.59259259, 0.59359359, 0.59459459,\n",
       "       0.5955956 , 0.5965966 , 0.5975976 , 0.5985986 , 0.5995996 ,\n",
       "       0.6006006 , 0.6016016 , 0.6026026 , 0.6036036 , 0.6046046 ,\n",
       "       0.60560561, 0.60660661, 0.60760761, 0.60860861, 0.60960961,\n",
       "       0.61061061, 0.61161161, 0.61261261, 0.61361361, 0.61461461,\n",
       "       0.61561562, 0.61661662, 0.61761762, 0.61861862, 0.61961962,\n",
       "       0.62062062, 0.62162162, 0.62262262, 0.62362362, 0.62462462,\n",
       "       0.62562563, 0.62662663, 0.62762763, 0.62862863, 0.62962963,\n",
       "       0.63063063, 0.63163163, 0.63263263, 0.63363363, 0.63463463,\n",
       "       0.63563564, 0.63663664, 0.63763764, 0.63863864, 0.63963964,\n",
       "       0.64064064, 0.64164164, 0.64264264, 0.64364364, 0.64464464,\n",
       "       0.64564565, 0.64664665, 0.64764765, 0.64864865, 0.64964965,\n",
       "       0.65065065, 0.65165165, 0.65265265, 0.65365365, 0.65465465,\n",
       "       0.65565566, 0.65665666, 0.65765766, 0.65865866, 0.65965966,\n",
       "       0.66066066, 0.66166166, 0.66266266, 0.66366366, 0.66466466,\n",
       "       0.66566567, 0.66666667, 0.66766767, 0.66866867, 0.66966967,\n",
       "       0.67067067, 0.67167167, 0.67267267, 0.67367367, 0.67467467,\n",
       "       0.67567568, 0.67667668, 0.67767768, 0.67867868, 0.67967968,\n",
       "       0.68068068, 0.68168168, 0.68268268, 0.68368368, 0.68468468,\n",
       "       0.68568569, 0.68668669, 0.68768769, 0.68868869, 0.68968969,\n",
       "       0.69069069, 0.69169169, 0.69269269, 0.69369369, 0.69469469,\n",
       "       0.6956957 , 0.6966967 , 0.6976977 , 0.6986987 , 0.6996997 ,\n",
       "       0.7007007 , 0.7017017 , 0.7027027 , 0.7037037 , 0.7047047 ,\n",
       "       0.70570571, 0.70670671, 0.70770771, 0.70870871, 0.70970971,\n",
       "       0.71071071, 0.71171171, 0.71271271, 0.71371371, 0.71471471,\n",
       "       0.71571572, 0.71671672, 0.71771772, 0.71871872, 0.71971972,\n",
       "       0.72072072, 0.72172172, 0.72272272, 0.72372372, 0.72472472,\n",
       "       0.72572573, 0.72672673, 0.72772773, 0.72872873, 0.72972973,\n",
       "       0.73073073, 0.73173173, 0.73273273, 0.73373373, 0.73473473,\n",
       "       0.73573574, 0.73673674, 0.73773774, 0.73873874, 0.73973974,\n",
       "       0.74074074, 0.74174174, 0.74274274, 0.74374374, 0.74474474,\n",
       "       0.74574575, 0.74674675, 0.74774775, 0.74874875, 0.74974975,\n",
       "       0.75075075, 0.75175175, 0.75275275, 0.75375375, 0.75475475,\n",
       "       0.75575576, 0.75675676, 0.75775776, 0.75875876, 0.75975976,\n",
       "       0.76076076, 0.76176176, 0.76276276, 0.76376376, 0.76476476,\n",
       "       0.76576577, 0.76676677, 0.76776777, 0.76876877, 0.76976977,\n",
       "       0.77077077, 0.77177177, 0.77277277, 0.77377377, 0.77477477,\n",
       "       0.77577578, 0.77677678, 0.77777778, 0.77877878, 0.77977978,\n",
       "       0.78078078, 0.78178178, 0.78278278, 0.78378378, 0.78478478,\n",
       "       0.78578579, 0.78678679, 0.78778779, 0.78878879, 0.78978979,\n",
       "       0.79079079, 0.79179179, 0.79279279, 0.79379379, 0.79479479,\n",
       "       0.7957958 , 0.7967968 , 0.7977978 , 0.7987988 , 0.7997998 ,\n",
       "       0.8008008 , 0.8018018 , 0.8028028 , 0.8038038 , 0.8048048 ,\n",
       "       0.80580581, 0.80680681, 0.80780781, 0.80880881, 0.80980981,\n",
       "       0.81081081, 0.81181181, 0.81281281, 0.81381381, 0.81481481,\n",
       "       0.81581582, 0.81681682, 0.81781782, 0.81881882, 0.81981982,\n",
       "       0.82082082, 0.82182182, 0.82282282, 0.82382382, 0.82482482,\n",
       "       0.82582583, 0.82682683, 0.82782783, 0.82882883, 0.82982983,\n",
       "       0.83083083, 0.83183183, 0.83283283, 0.83383383, 0.83483483,\n",
       "       0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984,\n",
       "       0.84084084, 0.84184184, 0.84284284, 0.84384384, 0.84484484,\n",
       "       0.84584585, 0.84684685, 0.84784785, 0.84884885, 0.84984985,\n",
       "       0.85085085, 0.85185185, 0.85285285, 0.85385385, 0.85485485,\n",
       "       0.85585586, 0.85685686, 0.85785786, 0.85885886, 0.85985986,\n",
       "       0.86086086, 0.86186186, 0.86286286, 0.86386386, 0.86486486,\n",
       "       0.86586587, 0.86686687, 0.86786787, 0.86886887, 0.86986987,\n",
       "       0.87087087, 0.87187187, 0.87287287, 0.87387387, 0.87487487,\n",
       "       0.87587588, 0.87687688, 0.87787788, 0.87887888, 0.87987988,\n",
       "       0.88088088, 0.88188188, 0.88288288, 0.88388388, 0.88488488,\n",
       "       0.88588589, 0.88688689, 0.88788789, 0.88888889, 0.88988989,\n",
       "       0.89089089, 0.89189189, 0.89289289, 0.89389389, 0.89489489,\n",
       "       0.8958959 , 0.8968969 , 0.8978979 , 0.8988989 , 0.8998999 ,\n",
       "       0.9009009 , 0.9019019 , 0.9029029 , 0.9039039 , 0.9049049 ,\n",
       "       0.90590591, 0.90690691, 0.90790791, 0.90890891, 0.90990991,\n",
       "       0.91091091, 0.91191191, 0.91291291, 0.91391391, 0.91491491,\n",
       "       0.91591592, 0.91691692, 0.91791792, 0.91891892, 0.91991992,\n",
       "       0.92092092, 0.92192192, 0.92292292, 0.92392392, 0.92492492,\n",
       "       0.92592593, 0.92692693, 0.92792793, 0.92892893, 0.92992993,\n",
       "       0.93093093, 0.93193193, 0.93293293, 0.93393393, 0.93493493,\n",
       "       0.93593594, 0.93693694, 0.93793794, 0.93893894, 0.93993994,\n",
       "       0.94094094, 0.94194194, 0.94294294, 0.94394394, 0.94494494,\n",
       "       0.94594595, 0.94694695, 0.94794795, 0.94894895, 0.94994995,\n",
       "       0.95095095, 0.95195195, 0.95295295, 0.95395395, 0.95495495,\n",
       "       0.95595596, 0.95695696, 0.95795796, 0.95895896, 0.95995996,\n",
       "       0.96096096, 0.96196196, 0.96296296, 0.96396396, 0.96496496,\n",
       "       0.96596597, 0.96696697, 0.96796797, 0.96896897, 0.96996997,\n",
       "       0.97097097, 0.97197197, 0.97297297, 0.97397397, 0.97497497,\n",
       "       0.97597598, 0.97697698, 0.97797798, 0.97897898, 0.97997998,\n",
       "       0.98098098, 0.98198198, 0.98298298, 0.98398398, 0.98498498,\n",
       "       0.98598599, 0.98698699, 0.98798799, 0.98898899, 0.98998999,\n",
       "       0.99099099, 0.99199199, 0.99299299, 0.99399399, 0.99499499,\n",
       "       0.995996  , 0.996997  , 0.997998  , 0.998999  , 1.        ]), array([[0.97771387, 0.97771387, 0.97699497, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.95986622, 0.95986622, 0.94816054, ..., 0.        , 0.        ,\n",
       "        0.        ]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.8350809707845427)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([0.83474345, 0.83541849])\n",
       "names: {0: 'Fire', 1: 'Smoke'}\n",
       "nt_per_class: array([1391,  598])\n",
       "nt_per_image: array([911, 396])\n",
       "results_dict: {'metrics/precision(B)': 0.9377610194099005, 'metrics/recall(B)': 0.9002246575340545, 'metrics/mAP50(B)': 0.9256544087909512, 'metrics/mAP50-95(B)': 0.8350809707845427, 'fitness': 0.8350809707845427}\n",
       "save_dir: WindowsPath('C:/2308/Fire Detection.v1i.yolov11/run_fire_exp5/final_tuning')\n",
       "speed: {'preprocess': 0.11842572982926425, 'inference': 1.2784796757497698, 'loss': 0.00019189187426220725, 'postprocess': 0.7802565405271141}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=50,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    project='run_fire_exp5',\n",
    "    name='final_tuning',\n",
    "    plots=True,\n",
    "    patience=10          # 10 Epoch 개선 없으면 stop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a49c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\augmentation\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 206.498.0 MB/s, size: 52.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 10.8it/s 5.3s0.2s\n",
      "                   all        925       1989      0.933      0.884      0.919      0.825\n",
      "                  Fire        911       1391      0.943      0.938      0.957      0.829\n",
      "                 Smoke        396        598      0.924      0.829      0.881      0.822\n",
      "Speed: 0.3ms preprocess, 2.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val3\u001b[0m\n",
      "Evaluating model: C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\final_tuning\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 244.868.9 MB/s, size: 30.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 927.9Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 10.8it/s 5.4s0.2s\n",
      "                   all        925       1989      0.938        0.9      0.926      0.835\n",
      "                  Fire        911       1391      0.945      0.945      0.957      0.835\n",
      "                 Smoke        396        598      0.931      0.856      0.894      0.835\n",
      "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val4\u001b[0m\n",
      "Evaluating model: C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\freeze_backbone\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 294.6134.7 MB/s, size: 38.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 11.3it/s 5.1s0.2s\n",
      "                   all        925       1989      0.931      0.894      0.921      0.829\n",
      "                  Fire        911       1391      0.944      0.933      0.956      0.831\n",
      "                 Smoke        396        598      0.918      0.855      0.887      0.826\n",
      "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val5\u001b[0m\n",
      "Evaluating model: C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\regularization\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 295.396.9 MB/s, size: 44.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 11.2it/s 5.2s0.2s\n",
      "                   all        925       1989      0.935      0.896      0.926       0.83\n",
      "                  Fire        911       1391      0.945      0.934      0.958      0.829\n",
      "                 Smoke        396        598      0.925      0.858      0.893      0.831\n",
      "Speed: 0.3ms preprocess, 2.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val6\u001b[0m\n",
      "Evaluating model: C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\train\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 318.3122.5 MB/s, size: 40.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 11.1it/s 5.2s0.2s\n",
      "                   all        925       1989      0.939      0.892      0.926      0.839\n",
      "                  Fire        911       1391      0.955      0.935      0.959      0.841\n",
      "                 Smoke        396        598      0.924      0.849      0.892      0.836\n",
      "Speed: 0.1ms preprocess, 2.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val7\u001b[0m\n",
      "Evaluating model: C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\unfreeze_all\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 295.6111.4 MB/s, size: 40.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 2.2Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 10.9it/s 5.3s0.2s\n",
      "                   all        925       1989      0.937      0.888      0.926      0.833\n",
      "                  Fire        911       1391      0.952      0.932       0.96      0.835\n",
      "                 Smoke        396        598      0.922      0.844      0.892      0.831\n",
      "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val8\u001b[0m\n",
      "                                               model  \\\n",
      "0  C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\...   \n",
      "1  C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\...   \n",
      "2  C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\...   \n",
      "3  C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\...   \n",
      "4  C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\...   \n",
      "5  C:\\2308\\Fire Detection.v1i.yolov11\\run_test01\\...   \n",
      "\n",
      "                                  precision  \\\n",
      "0  [0.9430549945099421, 0.9236826793363252]   \n",
      "1  [0.9453299631160406, 0.9309050488431386]   \n",
      "2  [0.9439722175365396, 0.9175513354438276]   \n",
      "3  [0.9454479012192556, 0.9249386794594815]   \n",
      "4  [0.9554455347273939, 0.9235278109522296]   \n",
      "5   [0.9515481840504476, 0.922052690125285]   \n",
      "\n",
      "                                     recall   mAP@0.5  mAP@0.5-0.95  \n",
      "0  [0.9381739755571531, 0.8294314381270903]  0.919138      0.825483  \n",
      "1   [0.944757940001828, 0.8561335811558579]  0.925653      0.834679  \n",
      "2  [0.9326515725480824, 0.8545150501672241]  0.921282      0.828553  \n",
      "3  [0.9344591169755914, 0.8578595317725752]  0.925676      0.829982  \n",
      "4  [0.9352983465132998, 0.8494983277591973]  0.925753      0.838522  \n",
      "5   [0.931831886372953, 0.8444816053511706]  0.925943      0.833326  \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 경로 리스트 (6개)\n",
    "model_paths=[\n",
    "    \"C:\\\\2308\\\\Fire Detection.v1i.yolov11\\\\run_test01\\\\augmentation\\\\weights\\\\best.pt\",\n",
    "    \"C:\\\\2308\\\\Fire Detection.v1i.yolov11\\\\run_test01\\\\final_tuning\\\\weights\\\\best.pt\",\n",
    "    \"C:\\\\2308\\\\Fire Detection.v1i.yolov11\\\\run_test01\\\\freeze_backbone\\\\weights\\\\best.pt\",\n",
    "    \"C:\\\\2308\\\\Fire Detection.v1i.yolov11\\\\run_test01\\\\regularization\\\\weights\\\\best.pt\",\n",
    "    \"C:\\\\2308\\\\Fire Detection.v1i.yolov11\\\\run_test01\\\\train\\\\weights\\\\best.pt\",\n",
    "    \"C:\\\\2308\\\\Fire Detection.v1i.yolov11\\\\run_test01\\\\unfreeze_all\\\\weights\\\\best.pt\"\n",
    "]\n",
    "\n",
    "# 평가용 데이터 설정\n",
    "data_yaml = \"data.yaml\"  # 검증/테스트 데이터의 yaml 설정 파일\n",
    "\n",
    "# IOU 기준 혹은 기타 평가 옵션들\n",
    "iou_thresholds = [0.5, 0.5]  # mAP50만 할 건지, mAP50-95 같이 할 건지 등\n",
    "\n",
    "# 결과 저장할 리스트\n",
    "results = []\n",
    "\n",
    "for mp in model_paths:\n",
    "    print(f\"Evaluating model: {mp}\")\n",
    "    model = YOLO(mp)\n",
    "    res = model.val(data=data_yaml)\n",
    "\n",
    "    # Corrected attribute names\n",
    "    precision = res.box.p  # Changed from res.box.precision\n",
    "    recall = res.box.r     # Changed from res.box.recall\n",
    "    map50 = res.box.map50\n",
    "    map50_95 = res.box.map\n",
    "\n",
    "    results.append({\n",
    "        \"model\": mp,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"mAP@0.5\": map50,\n",
    "        \"mAP@0.5-0.95\": map50_95\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7995666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: run_test01\\augmentation\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 205.077.7 MB/s, size: 47.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 10.7it/s 5.4s0.2s\n",
      "                   all        925       1989      0.933      0.884      0.919      0.825\n",
      "                  Fire        911       1391      0.943      0.938      0.957      0.829\n",
      "                 Smoke        396        598      0.924      0.829      0.881      0.822\n",
      "Speed: 0.3ms preprocess, 2.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val9\u001b[0m\n",
      "Evaluating model: run_test01\\final_tuning\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 324.3117.2 MB/s, size: 43.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 925.3Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 10.6it/s 5.5s0.2s\n",
      "                   all        925       1989      0.938        0.9      0.926      0.835\n",
      "                  Fire        911       1391      0.945      0.945      0.957      0.835\n",
      "                 Smoke        396        598      0.931      0.856      0.894      0.835\n",
      "Speed: 0.3ms preprocess, 2.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val10\u001b[0m\n",
      "Evaluating model: run_test01\\freeze_backbone\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 340.6138.6 MB/s, size: 46.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 924.4Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 11.3it/s 5.1s0.2s\n",
      "                   all        925       1989      0.931      0.894      0.921      0.829\n",
      "                  Fire        911       1391      0.944      0.933      0.956      0.831\n",
      "                 Smoke        396        598      0.918      0.855      0.887      0.826\n",
      "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val11\u001b[0m\n",
      "Evaluating model: run_test01\\regularization\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 325.9126.7 MB/s, size: 41.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925 2.6Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 11.2it/s 5.2s0.1s\n",
      "                   all        925       1989      0.935      0.896      0.926       0.83\n",
      "                  Fire        911       1391      0.945      0.934      0.958      0.829\n",
      "                 Smoke        396        598      0.925      0.858      0.893      0.831\n",
      "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val12\u001b[0m\n",
      "Evaluating model: run_test01\\train\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 401.2180.1 MB/s, size: 50.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 11.2it/s 5.2s0.1s\n",
      "                   all        925       1989      0.939      0.892      0.926      0.839\n",
      "                  Fire        911       1391      0.955      0.935      0.959      0.841\n",
      "                 Smoke        396        598      0.924      0.849      0.892      0.836\n",
      "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val13\u001b[0m\n",
      "Evaluating model: run_test01\\unfreeze_all\\weights\\best.pt\n",
      "Ultralytics 8.3.202  Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A4000, 16376MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 307.850.7 MB/s, size: 43.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\2308\\Fire Detection.v1i.yolov11\\valid\\labels.cache... 925 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 925/925  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 58/58 11.1it/s 5.2s0.1s\n",
      "                   all        925       1989      0.937      0.888      0.926      0.833\n",
      "                  Fire        911       1391      0.952      0.932       0.96      0.835\n",
      "                 Smoke        396        598      0.922      0.844      0.892      0.831\n",
      "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\2308\\Fire Detection.v1i.yolov11\\runs\\detect\\val14\u001b[0m\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/models.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     36\u001b[39m df = pd.DataFrame(\n\u001b[32m     37\u001b[39m     results,\n\u001b[32m     38\u001b[39m     columns=[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmAP@0.5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmAP@0.5-0.95\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     39\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# CSV 파일로 저장\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/models.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8-sig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\anaconda3\\envs\\test021\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3891\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3893\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3894\u001b[39m     frame=df,\n\u001b[32m   3895\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3899\u001b[39m     decimal=decimal,\n\u001b[32m   3900\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3902\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3905\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3907\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\anaconda3\\envs\\test021\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m   1131\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1133\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m   1134\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m   1135\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1150\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1151\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1155\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\anaconda3\\envs\\test021\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    257\u001b[39m         handles.handle,\n\u001b[32m    258\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    263\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    264\u001b[39m     )\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\anaconda3\\envs\\test021\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    862\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    872\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/models.csv'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 경로 리스트 (6개)\n",
    "model_paths = [\n",
    "    \"run_test01\\\\augmentation\\\\weights\\\\best.pt\",\n",
    "    \"run_test01\\\\final_tuning\\\\weights\\\\best.pt\",\n",
    "    \"run_test01\\\\freeze_backbone\\\\weights\\\\best.pt\",\n",
    "    \"run_test01\\\\regularization\\\\weights\\\\best.pt\",\n",
    "    \"run_test01\\\\train\\\\weights\\\\best.pt\",\n",
    "    \"run_test01\\\\unfreeze_all\\\\weights\\\\best.pt\"\n",
    "]\n",
    "\n",
    "# 평가용 데이터 설정\n",
    "data_yaml = \"data.yaml\"  # 검증/테스트 데이터의 yaml 설정 파일\n",
    "\n",
    "# 결과 저장할 리스트\n",
    "results = []\n",
    "\n",
    "for mp in model_paths:\n",
    "    print(f\"Evaluating model: {mp}\")\n",
    "    model = YOLO(mp)\n",
    "    res = model.val(data=data_yaml)\n",
    "\n",
    "    # 올바른 속성 접근 (YOLOv11 기준)\n",
    "    precision = res.box.p      # precision\n",
    "    recall = res.box.r         # recall\n",
    "    map50 = res.box.map50      # mAP@0.5\n",
    "    map50_95 = res.box.map     # mAP@0.5:0.95\n",
    "\n",
    "    results.append([\n",
    "        mp, precision, recall, map50, map50_95\n",
    "    ])\n",
    "\n",
    "# DataFrame 변환\n",
    "df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"precision\", \"recall\", \"mAP@0.5\", \"mAP@0.5-0.95\"]\n",
    ")\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv(\"models.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b13b5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"models.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f24f83dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mAP@0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mAP@0.5-0.95",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2c98c7c5-4f86-4f5d-8d4f-349679b39817",
       "rows": [
        [
         "0",
         "Augmentation",
         "[    0.94305     0.92368]",
         "[    0.93817     0.82943]",
         "0.9191381230452472",
         "0.8254833660800107"
        ],
        [
         "1",
         "Final Tuning",
         "[    0.94533     0.93091]",
         "[    0.94476     0.85613]",
         "0.9256528578840332",
         "0.8346789333935505"
        ],
        [
         "2",
         "Freeze Backbone",
         "[    0.94397     0.91755]",
         "[    0.93265     0.85452]",
         "0.9212823405740962",
         "0.8285533063990389"
        ],
        [
         "3",
         "Regularization",
         "[    0.94545     0.92494]",
         "[    0.93446     0.85786]",
         "0.9256756914648598",
         "0.8299819222325209"
        ],
        [
         "4",
         "Base Training",
         "[    0.95545     0.92353]",
         "[     0.9353      0.8495]",
         "0.9257533295191502",
         "0.8385223879330734"
        ],
        [
         "5",
         "Unfreeze All",
         "[    0.95155     0.92205]",
         "[    0.93183     0.84448]",
         "0.9259428298606768",
         "0.8333257405562382"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mAP@0.5</th>\n",
       "      <th>mAP@0.5-0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Augmentation</td>\n",
       "      <td>[    0.94305     0.92368]</td>\n",
       "      <td>[    0.93817     0.82943]</td>\n",
       "      <td>0.919138</td>\n",
       "      <td>0.825483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final Tuning</td>\n",
       "      <td>[    0.94533     0.93091]</td>\n",
       "      <td>[    0.94476     0.85613]</td>\n",
       "      <td>0.925653</td>\n",
       "      <td>0.834679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Freeze Backbone</td>\n",
       "      <td>[    0.94397     0.91755]</td>\n",
       "      <td>[    0.93265     0.85452]</td>\n",
       "      <td>0.921282</td>\n",
       "      <td>0.828553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regularization</td>\n",
       "      <td>[    0.94545     0.92494]</td>\n",
       "      <td>[    0.93446     0.85786]</td>\n",
       "      <td>0.925676</td>\n",
       "      <td>0.829982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base Training</td>\n",
       "      <td>[    0.95545     0.92353]</td>\n",
       "      <td>[     0.9353      0.8495]</td>\n",
       "      <td>0.925753</td>\n",
       "      <td>0.838522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unfreeze All</td>\n",
       "      <td>[    0.95155     0.92205]</td>\n",
       "      <td>[    0.93183     0.84448]</td>\n",
       "      <td>0.925943</td>\n",
       "      <td>0.833326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model                  precision                     recall  \\\n",
       "0     Augmentation  [    0.94305     0.92368]  [    0.93817     0.82943]   \n",
       "1     Final Tuning  [    0.94533     0.93091]  [    0.94476     0.85613]   \n",
       "2  Freeze Backbone  [    0.94397     0.91755]  [    0.93265     0.85452]   \n",
       "3   Regularization  [    0.94545     0.92494]  [    0.93446     0.85786]   \n",
       "4    Base Training  [    0.95545     0.92353]  [     0.9353      0.8495]   \n",
       "5     Unfreeze All  [    0.95155     0.92205]  [    0.93183     0.84448]   \n",
       "\n",
       "    mAP@0.5  mAP@0.5-0.95  \n",
       "0  0.919138      0.825483  \n",
       "1  0.925653      0.834679  \n",
       "2  0.921282      0.828553  \n",
       "3  0.925676      0.829982  \n",
       "4  0.925753      0.838522  \n",
       "5  0.925943      0.833326  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv('models.csv')\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c78c32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.drop([1,2],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f833d22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mAP@0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mAP@0.5-0.95",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ae7d9dc5-861d-4c0f-a183-60e226deea63",
       "rows": [
        [
         "0",
         "Augmentation",
         "[    0.94305     0.92368]",
         "[    0.93817     0.82943]",
         "0.9191381230452472",
         "0.8254833660800107"
        ],
        [
         "3",
         "Regularization",
         "[    0.94545     0.92494]",
         "[    0.93446     0.85786]",
         "0.9256756914648598",
         "0.8299819222325209"
        ],
        [
         "4",
         "Base Training",
         "[    0.95545     0.92353]",
         "[     0.9353      0.8495]",
         "0.9257533295191502",
         "0.8385223879330734"
        ],
        [
         "5",
         "Unfreeze All",
         "[    0.95155     0.92205]",
         "[    0.93183     0.84448]",
         "0.9259428298606768",
         "0.8333257405562382"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mAP@0.5</th>\n",
       "      <th>mAP@0.5-0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Augmentation</td>\n",
       "      <td>[    0.94305     0.92368]</td>\n",
       "      <td>[    0.93817     0.82943]</td>\n",
       "      <td>0.919138</td>\n",
       "      <td>0.825483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regularization</td>\n",
       "      <td>[    0.94545     0.92494]</td>\n",
       "      <td>[    0.93446     0.85786]</td>\n",
       "      <td>0.925676</td>\n",
       "      <td>0.829982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base Training</td>\n",
       "      <td>[    0.95545     0.92353]</td>\n",
       "      <td>[     0.9353      0.8495]</td>\n",
       "      <td>0.925753</td>\n",
       "      <td>0.838522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unfreeze All</td>\n",
       "      <td>[    0.95155     0.92205]</td>\n",
       "      <td>[    0.93183     0.84448]</td>\n",
       "      <td>0.925943</td>\n",
       "      <td>0.833326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model                  precision                     recall  \\\n",
       "0    Augmentation  [    0.94305     0.92368]  [    0.93817     0.82943]   \n",
       "3  Regularization  [    0.94545     0.92494]  [    0.93446     0.85786]   \n",
       "4   Base Training  [    0.95545     0.92353]  [     0.9353      0.8495]   \n",
       "5    Unfreeze All  [    0.95155     0.92205]  [    0.93183     0.84448]   \n",
       "\n",
       "    mAP@0.5  mAP@0.5-0.95  \n",
       "0  0.919138      0.825483  \n",
       "3  0.925676      0.829982  \n",
       "4  0.925753      0.838522  \n",
       "5  0.925943      0.833326  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6e62ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.drop([5],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdc21dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             model                  precision                     recall  \\\n",
      "0     Augmentation  [    0.94305     0.92368]  [    0.93817     0.82943]   \n",
      "1     Final Tuning  [    0.94533     0.93091]  [    0.94476     0.85613]   \n",
      "2  Freeze Backbone  [    0.94397     0.91755]  [    0.93265     0.85452]   \n",
      "3   Regularization  [    0.94545     0.92494]  [    0.93446     0.85786]   \n",
      "4    Base Training  [    0.95545     0.92353]  [     0.9353      0.8495]   \n",
      "5     Unfreeze All  [    0.95155     0.92205]  [    0.93183     0.84448]   \n",
      "\n",
      "    mAP@0.5  mAP@0.5-0.95  \n",
      "0  0.919138      0.825483  \n",
      "1  0.925653      0.834679  \n",
      "2  0.921282      0.828553  \n",
      "3  0.925676      0.829982  \n",
      "4  0.925753      0.838522  \n",
      "5  0.925943      0.833326  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. 새로운 모델 이름 리스트 (행 수와 동일하게)\n",
    "new_model_names = [\n",
    "    \"Augmentation\",\n",
    "    \"Regularization\",\n",
    "    \"Base Training\"\n",
    "]\n",
    "\n",
    "# 3. model 컬럼 교체\n",
    "csv[\"model\"] = new_model_names\n",
    "\n",
    "# 4. 출력 확인\n",
    "print(df)\n",
    "\n",
    "# 5. CSV로 저장\n",
    "df.to_csv(\"models02.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c09425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
